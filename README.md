# Project05-NLP_ANALISIS_SENTIMIENTOS

# 游늵 **Informe Final: An치lisis de Sentimiento en Reviews de Videojuegos**

## 游늷 **1. Introducci칩n**

En este proyecto se ha desarrollado un modelo de **an치lisis de sentimiento** aplicado a rese침as de videojuegos. El objetivo era clasificar las rese침as en **positivas** o **negativas**, utilizando t칠cnicas de procesamiento de lenguaje natural (NLP) y modelos de machine learning.

## 游늷 **2. Preprocesamiento de Datos**

- Se ha utilizado un dataset de rese침as de videojuegos, eliminando valores nulos y realizando limpieza de texto.
- Se ha aplicado **tokenizaci칩n optimizada con GPU** mediante `spaCy`.
- Para la vectorizaci칩n del texto, se ha combinado **TF-IDF** con **Word2Vec**, con el objetivo de capturar tanto la frecuencia como la sem치ntica de las palabras.
- Se ha utilizado **SMOTE** para balancear las clases y evitar problemas de desbalanceo en los datos de entrenamiento.

## 游늷 **3. Modelos Entrenados y Comparaci칩n**

Se han probado los siguientes modelos:

- **Regresi칩n Log칤stica**
- **Random Forest**
- **XGBoost** (con aceleraci칩n en GPU)
- **LightGBM** (con aceleraci칩n en GPU)

Para la selecci칩n del mejor modelo, se evaluaron las siguientes m칠tricas:

- **Accuracy**
- **Precision**
- **Recall**
- **F1-score**
- **Curva ROC y AUC**

## 游늷 **4. Resultados**

Los modelos presentaron los siguientes desempe침os:

| Modelo              | Accuracy | Precision | Recall | F1-score | AUC  |
| ------------------- | -------- | --------- | ------ | -------- | ---- |
| Regresi칩n Log칤stica | 0.79     | 0.80      | 0.96   | 0.87     | 0.77 |
| Random Forest       | 0.83     | 0.86      | 0.93   | 0.89     | 0.84 |
| XGBoost             | 0.79     | 0.86      | 0.87   | 0.87     | 0.79 |
| LightGBM            | 0.80     | 0.87      | 0.88   | 0.87     | 0.81 |

El **mejor modelo seg칰n las m칠tricas** fue **Random Forest**, seguido de **LightGBM**, ambos con una buena combinaci칩n de **precisi칩n** y **recall**.

## 游늷 **5. Visualizaciones Clave**

Se han generado diversas visualizaciones para el an치lisis del modelo:

- **Matriz de Confusi칩n**: Para evaluar los errores de clasificaci칩n.
- **Curva ROC y AUC**: Para comparar la capacidad predictiva de los modelos.
- **Distribuci칩n de Probabilidades de Predicci칩n**: Para analizar la confianza de las predicciones.

## 游늷 **6. Predicciones sobre Nuevas Frases**

Se realizaron pruebas con frases nuevas y el modelo fue capaz de clasificar correctamente rese침as positivas y negativas. Esto valida su capacidad para generalizar a datos no vistos.

## 游늷 **7. Conclusiones y Futuras Mejoras**

**Conclusiones:**

- La combinaci칩n de **TF-IDF y Word2Vec** ha sido efectiva para capturar la sem치ntica del texto.
- **Random Forest** ha demostrado ser el modelo m치s robusto en t칠rminos de balance entre precisi칩n y recall.
- El balanceo de clases con **SMOTE** ha mejorado significativamente el rendimiento del modelo.

**Posibles Mejoras:**

- Implementar modelos m치s avanzados como **BERT o Transformers** para mejorar el rendimiento.
- Incluir m칠tricas de interpretabilidad, como la importancia de palabras en los modelos de 치rboles.
- Ampliar el dataset con m치s rese침as para mejorar la generalizaci칩n del modelo.




